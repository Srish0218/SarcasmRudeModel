{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMLOMwnm1NjrTPawi6mCZuj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Srish0218/SarcasmRudeModel/blob/main/SarcasmRudeModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas tqdm regex scipy tiktoken"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24iqXl6LyRr7",
        "outputId": "43b3f781-ecdc-44c3-fc4f-1659e3c37e01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (2024.5.15)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.6.2)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install openai==0.28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eR4UTT6gqnyy",
        "outputId": "3b2e200d-fe37-4faa-8fec-5352530f8630"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.6.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "import ast\n",
        "import tiktoken\n",
        "from scipy import spatial\n",
        "import time\n",
        "import regex as re\n",
        "from tqdm import tqdm\n",
        "import json"
      ],
      "metadata": {
        "id": "E5-Yad1mqoy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tqdm.pandas()\n"
      ],
      "metadata": {
        "id": "FyT3v8cxyItu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tick = time.time()\n"
      ],
      "metadata": {
        "id": "NBU3gxOZyiYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('OutPut Details - Cred- Parameter.xlsx', sheet_name='Transcript Chat')\n"
      ],
      "metadata": {
        "id": "R5XFBqknqrs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ox5vQkHL2spB",
        "outputId": "e7bb5be0-4068-472c-8337-4dae92477f12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'request_id', 'Conversation ID', 'transcript', 'speaker',\n",
              "       'sentiment', 'sentiment_score', 'starttime', 'Endtime', 'Holddiff',\n",
              "       'Dear_Air_short', 'Dear_Air_long'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key =\n"
      ],
      "metadata": {
        "id": "gOWwjgDjqxhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0jTheJVtzfWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not all(col in df.columns for col in ['Conversation ID', 'speaker', 'transcript']):\n",
        "    raise ValueError(\"The dataset must include ['Conversation ID', 'speaker', 'transcript']\")\n"
      ],
      "metadata": {
        "id": "sR--hYOrzbMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UFNCw8SHzf8o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Td2kKA0YqbY9"
      },
      "outputs": [],
      "source": [
        "rules = \"\"\"\n",
        "Follow below instructions strictly to check if the agent is being rude with the customer in the chat conversation.\n",
        "\n",
        "You need to figure out if the agent was rude at any point in time during the conversation and give deterministic\n",
        "and standard output every time for the same prompt.\n",
        "Please mark the output as \"Yes\" if you find the conversation rude else \"No\".\n",
        "Also give a reason why you have marked it as Yes or No.\n",
        "For example, if you are marking it as Yes, then give the exact rude statement used by the agent in the chat conversation.\n",
        "\"\"\"\n",
        "\n",
        "example = \"\"\"\n",
        "Give Output strictly in the following JSON format after the explanation:\n",
        "\n",
        "{\n",
        "    \"audit_outcome\": (Yes or No),\n",
        "    \"reasons\": [reason]\n",
        "}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prompt(TICKET_ID, audit_rules, example_out, df):\n",
        "    single_chat = df[df['request_id'] == TICKET_ID]\n",
        "    single_chat.reset_index(inplace=True)\n",
        "    single_chat = single_chat[['speaker', 'transcript']]\n",
        "\n",
        "    first_occurance = -1\n",
        "    second_occurance = -1\n",
        "\n",
        "    for index, row in single_chat.iterrows():\n",
        "        if 'has joined the conversation' in row['transcript']:\n",
        "            if first_occurance == -1:\n",
        "                first_occurance = index\n",
        "            else:\n",
        "                second_occurance = index\n",
        "                break\n",
        "\n",
        "    if second_occurance != -1:\n",
        "        only_first_agent_single_chat = single_chat.iloc[0:second_occurance]\n",
        "    else:\n",
        "        only_first_agent_single_chat = single_chat\n",
        "\n",
        "    convo = ''\n",
        "    for i in range(len(only_first_agent_single_chat)):\n",
        "        if only_first_agent_single_chat.iloc[i]['speaker'] == 'bot':\n",
        "            continue\n",
        "        if 'assisting you today' in only_first_agent_single_chat.iloc[i]['transcript']:\n",
        "            continue\n",
        "        if 'Welcome to' in only_first_agent_single_chat.iloc[i]['transcript']:\n",
        "            continue\n",
        "        speaker = 'Agent' if only_first_agent_single_chat.iloc[i]['speaker'] == 0 else 'Customer'\n",
        "        convo += f\"{speaker}: {only_first_agent_single_chat.iloc[i]['transcript']}\\n\"\n",
        "\n",
        "    prompt = f\"Audit the given chat based on the audit rules and chat conversation given below\\n\\n\\nBelow is a chat conversation between customer care agent and a customer\\n\\n```\\n{convo}\\n\\n```\\n{audit_rules}{example_out}\"\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "2IQ97f7Wq2zH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_response(prompt):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"Imagine you are the best customer experience quality auditor in a company. Your primary responsibility is to comprehensively and contextually evaluate the chat transcript between the agent and the customer.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt},\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model='gpt-3.5-turbo',\n",
        "            messages=messages,\n",
        "            temperature=0\n",
        "        )\n",
        "        response_message = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        response_message = '''\n",
        "        {\n",
        "            \"audit_outcome\": \"Error\",\n",
        "            \"reasons\": []\n",
        "        }\n",
        "        '''\n",
        "\n",
        "    return response_message"
      ],
      "metadata": {
        "id": "lXGk4CCbqkqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ticket_list = list(df['request_id'].unique())\n"
      ],
      "metadata": {
        "id": "bIQziL62q5tF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = pd.DataFrame(ticket_list, columns=['request_id'])\n"
      ],
      "metadata": {
        "id": "C3VXOQ4as90y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res['JSON_OUT'] = res['request_id'].progress_apply(lambda x: get_response(get_prompt(x, rules, example, df)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xkyRWlQtAwa",
        "outputId": "0b6ac978-3f6d-4b3c-897a-4e295b5f0ba9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 218/218 [04:03<00:00,  1.12s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ea_out(x):\n",
        "    try:\n",
        "        return json.loads(x)['audit_outcome']\n",
        "    except Exception as e:\n",
        "        print(f\"Error in ea_out: {e}\")\n",
        "        return 'Error'\n",
        "\n",
        "def ea_reasons(x):\n",
        "    try:\n",
        "        return json.loads(x)['reasons']\n",
        "    except Exception as e:\n",
        "        print(f\"Error in ea_reasons: {e}\")\n",
        "        return ['Error']\n",
        "\n",
        "def remove_extra_text(x):\n",
        "    only_json = ''\n",
        "    read = False\n",
        "    for c in x:\n",
        "        if c == '{':\n",
        "            read = True\n",
        "        if read:\n",
        "            only_json += c\n",
        "        if c == '}':\n",
        "            break\n",
        "    return only_json"
      ],
      "metadata": {
        "id": "B4VvGEfrtZSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res['Output'] = res['JSON_OUT'].apply(lambda x: ea_out(remove_extra_text(x)))\n",
        "res['Evidence'] = res['JSON_OUT'].apply(lambda x: ea_reasons(remove_extra_text(x)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgtT6SOI09DN",
        "outputId": "62286573-857a-419a-9234-1b5522ec4871"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in ea_out: Invalid control character at: line 3 column 605 (char 634)\n",
            "Error in ea_reasons: Invalid control character at: line 3 column 605 (char 634)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res.to_csv('Rude_Out.csv', index=False)\n"
      ],
      "metadata": {
        "id": "0WCt1lP_0_Ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SarcasmRude = res\n",
        "Main = pd.read_excel('CRED_organised_result_12June10am.xlsx')\n",
        "\n",
        "merged_df = pd.merge(Main,SarcasmRude,  on='request_id')\n"
      ],
      "metadata": {
        "id": "QKxjuD6F1A0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsjZg1GS6lRp",
        "outputId": "29b731c6-3d02-4dae-ed85-bac2fd9b8670"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['request_id', 'apology_found', 'total_apology_count',\n",
              "       'apology_evidence', 'empathy_found', 'total_empathy_count',\n",
              "       'empathy_evidence', 'hold_request_found', 'total_hold_count',\n",
              "       'hold_evidence', 'failure_to_assure', 'failure_to_assure_count',\n",
              "       'failure_to_assure_evidence', 'rude_found', 'rude_evidence',\n",
              "       'total_rude_behavior_count', 'sarcasm_prediction', 'sarcasm_evidence',\n",
              "       'sarcasm_count', 'english_customer_count', 'hindi_customer_count',\n",
              "       'english_agent_count', 'hindi_agent_count', 'language_switch',\n",
              "       'JSON_OUT', 'Output', 'Evidence'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = merged_df.drop(columns=['JSON_OUT', 'rude_found', 'rude_evidence',\n",
        "       'total_rude_behavior_count', 'sarcasm_prediction', 'sarcasm_evidence',\n",
        "       'sarcasm_count'])\n",
        "merged_df = merged_df.rename(columns={'Output': 'Sarcasm_rude_behaviour', 'Evidence': 'Sarcasm_rude_behaviour_evidence'})\n"
      ],
      "metadata": {
        "id": "B7bB53wO4q56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_evidence(row):\n",
        "    if row['Sarcasm_rude_behaviour'] == 'Yes':\n",
        "        return row['Sarcasm_rude_behaviour_evidence']\n",
        "    else:\n",
        "        return 'No evidence for sarcasm and rude behavior found'\n",
        "\n",
        "merged_df['Sarcasm_rude_behaviour_evidence'] = merged_df.apply(update_evidence, axis=1)"
      ],
      "metadata": {
        "id": "2Br_R5II8Jkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kVu-tr7L7d3Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
